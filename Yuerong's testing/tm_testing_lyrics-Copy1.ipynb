{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove stopwords\n",
    "## we will replace this word list with our own list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Stopwords\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','na', 'la', 'ooh', 'oh', 'ah', 'ba', 'da', 'aye','be',\n",
    "                 'go','get','know','s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hanging moment</td>\n",
       "      <td>lifehouse</td>\n",
       "      <td>2001</td>\n",
       "      <td>im desperate changing starving truth im closer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>fallin</td>\n",
       "      <td>alicia keys</td>\n",
       "      <td>2001</td>\n",
       "      <td>keep fallin love sometimes love ya sometimes m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>janet</td>\n",
       "      <td>2001</td>\n",
       "      <td>girls party look body shakin thing like never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>drops jupiter tell</td>\n",
       "      <td>train</td>\n",
       "      <td>2001</td>\n",
       "      <td>back atmosphere drops jupiter hair hey acts li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>im real</td>\n",
       "      <td>jennifer lopez featuring ja rule</td>\n",
       "      <td>2001</td>\n",
       "      <td>called phone said im comin hope alone cause go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1461</td>\n",
       "      <td>95</td>\n",
       "      <td>waves</td>\n",
       "      <td>mr probz</td>\n",
       "      <td>2015</td>\n",
       "      <td>face water feet cant touch ground touch ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1462</td>\n",
       "      <td>96</td>\n",
       "      <td>el perdon</td>\n",
       "      <td>nicky jam and enrique iglesias</td>\n",
       "      <td>2015</td>\n",
       "      <td>enrique iglesias dime si es verdad dijeron que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1463</td>\n",
       "      <td>98</td>\n",
       "      <td>night changes</td>\n",
       "      <td>one direction</td>\n",
       "      <td>2015</td>\n",
       "      <td>going tonight changes something red mother lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464</td>\n",
       "      <td>99</td>\n",
       "      <td>back back</td>\n",
       "      <td>drake</td>\n",
       "      <td>2015</td>\n",
       "      <td>man man man againyeah learned game william wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1465</td>\n",
       "      <td>100</td>\n",
       "      <td>deep love</td>\n",
       "      <td>calvin harris and disciples</td>\n",
       "      <td>2015</td>\n",
       "      <td>want breathe let air let roam body freely inhi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank                Song                            Artist  Year  \\\n",
       "0        1      hanging moment                         lifehouse  2001   \n",
       "1        2              fallin                       alicia keys  2001   \n",
       "2        3                 NaN                             janet  2001   \n",
       "3        4  drops jupiter tell                             train  2001   \n",
       "4        5             im real  jennifer lopez featuring ja rule  2001   \n",
       "...    ...                 ...                               ...   ...   \n",
       "1461    95               waves                          mr probz  2015   \n",
       "1462    96           el perdon    nicky jam and enrique iglesias  2015   \n",
       "1463    98       night changes                     one direction  2015   \n",
       "1464    99           back back                             drake  2015   \n",
       "1465   100           deep love       calvin harris and disciples  2015   \n",
       "\n",
       "                                                 Lyrics  \n",
       "0     im desperate changing starving truth im closer...  \n",
       "1     keep fallin love sometimes love ya sometimes m...  \n",
       "2     girls party look body shakin thing like never ...  \n",
       "3     back atmosphere drops jupiter hair hey acts li...  \n",
       "4     called phone said im comin hope alone cause go...  \n",
       "...                                                 ...  \n",
       "1461  face water feet cant touch ground touch ground...  \n",
       "1462  enrique iglesias dime si es verdad dijeron que...  \n",
       "1463  going tonight changes something red mother lik...  \n",
       "1464  man man man againyeah learned game william wes...  \n",
       "1465  want breathe let air let roam body freely inhi...  \n",
       "\n",
       "[1466 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('../cleaned_data/billboard_lyrics_2001-2015.csv', encoding='cp1252')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df.Lyrics.values.tolist()\n",
    "#pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize words and Clean-up text\n",
    "- tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
    "- Gensim’s simple_preprocess() is great for this. Additionally I have set deacc=True to remove the punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "#print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Bigram and Trigram Models\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring.Some examples in our example are: ‘front_bumper’, ‘oil_leak’, ‘maryland_college_park’ etc.\n",
    "- Gensim’s Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold. \n",
    "- The higher the values of these param, the harder it is for words to be combined to bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "#print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords, Make Bigrams and Lemmatize\n",
    "- define the functions to remove the stopwords, make bigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "#print(stop_words)\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB']):#,'ADV'\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi', 'make', 'hi'], ['hi'], ['hihihi']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teststr = \"hi be be make hi\",'hi','hihihi'\n",
    "cleaned=remove_stopwords(teststr)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1466\n"
     ]
    }
   ],
   "source": [
    "print(type(data_words))\n",
    "print(len(data_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ','VERB'])#'ADV'\n",
    "\n",
    "#print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dictionary and Corpus needed for Topic Modeling\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "#print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'change'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a human-readable form of the corpus itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('be', 16),\n",
       "  ('change', 3),\n",
       "  ('chase', 2),\n",
       "  ('desperate', 2),\n",
       "  ('elseim', 1),\n",
       "  ('fall', 3),\n",
       "  ('fly', 1),\n",
       "  ('hanging_moment', 6),\n",
       "  ('have', 3),\n",
       "  ('ill', 1),\n",
       "  ('incomplete', 1),\n",
       "  ('invitation', 1),\n",
       "  ('lack', 1),\n",
       "  ('leave', 1),\n",
       "  ('let', 3),\n",
       "  ('lose', 1),\n",
       "  ('love', 3),\n",
       "  ('make', 3),\n",
       "  ('menow', 1),\n",
       "  ('mind', 1),\n",
       "  ('move', 3),\n",
       "  ('run', 2),\n",
       "  ('s', 1),\n",
       "  ('stand', 3),\n",
       "  ('start', 2),\n",
       "  ('starve', 2),\n",
       "  ('sure', 2),\n",
       "  ('take', 2),\n",
       "  ('thing', 2),\n",
       "  ('truth', 2),\n",
       "  ('tune', 2),\n",
       "  ('world', 1),\n",
       "  ('would', 2),\n",
       "  ('youforgette', 1),\n",
       "  ('youim', 2)]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the corpus and dictionary, you need to provide the number of topics.\n",
    "\n",
    "- Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior.\n",
    "\n",
    "- chunksize is the number of documents to be used in each training chunk. update_every determines how often the model parameters should be updated and passes is the total number of training passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.245*\"little\" + 0.127*\"work\" + 0.061*\"waste\" + 0.029*\"middle\" + '\n",
      "  '0.026*\"goodbye\" + 0.025*\"safe\" + 0.021*\"sittin\" + 0.018*\"welcome\" + '\n",
      "  '0.018*\"quit\" + 0.017*\"enough\"'),\n",
      " (1,\n",
      "  '0.425*\"go\" + 0.142*\"night\" + 0.098*\"come\" + 0.034*\"head\" + 0.032*\"break\" + '\n",
      "  '0.028*\"play\" + 0.018*\"rain\" + 0.016*\"help\" + 0.012*\"pour\" + 0.012*\"ready\"'),\n",
      " (2,\n",
      "  '0.271*\"world\" + 0.125*\"people\" + 0.049*\"beauty\" + 0.007*\"meall\" + '\n",
      "  '0.004*\"ur_freak\" + 0.003*\"power\" + 0.000*\"shake_shake\" + 0.000*\"champion\" + '\n",
      "  '0.000*\"bout_bas\" + 0.000*\"mama\"'),\n",
      " (3,\n",
      "  '0.302*\"remember\" + 0.000*\"remember_centurie\" + 0.000*\"history\" + '\n",
      "  '0.000*\"legend\" + 0.000*\"dust\" + 0.000*\"wildest_dream\" + '\n",
      "  '0.000*\"ohohohoh_ohohohoh\" + 0.000*\"danced\" + 0.000*\"cheek\" + 0.000*\"rosy\"'),\n",
      " (4,\n",
      "  '0.076*\"scared\" + 0.028*\"handle\" + 0.000*\"drives_insane\" + 0.000*\"cruel\" + '\n",
      "  '0.000*\"haooh\" + 0.000*\"lump_throat\" + 0.000*\"riptide\" + 0.000*\"doneyou\" + '\n",
      "  '0.000*\"follower\" + 0.000*\"soldier\"'),\n",
      " (5,\n",
      "  '0.232*\"good\" + 0.200*\"turn\" + 0.115*\"light\" + 0.024*\"bear\" + 0.021*\"drink\" '\n",
      "  '+ 0.020*\"home\" + 0.019*\"bed\" + 0.017*\"dumb\" + 0.017*\"midnight\" + '\n",
      "  '0.016*\"sexy\"'),\n",
      " (6,\n",
      "  '0.352*\"be\" + 0.092*\"get\" + 0.067*\"say\" + 0.043*\"s\" + 0.035*\"tell\" + '\n",
      "  '0.017*\"call\" + 0.013*\"give\" + 0.013*\"real\" + 0.012*\"man\" + 0.012*\"hate\"'),\n",
      " (7,\n",
      "  '0.040*\"make\" + 0.028*\"be\" + 0.026*\"fuck\" + 0.025*\"bitch\" + 0.023*\"get\" + '\n",
      "  '0.022*\"put\" + 0.016*\"shit\" + 0.014*\"nigga\" + 0.014*\"name\" + 0.012*\"well\"'),\n",
      " (8,\n",
      "  '0.422*\"take\" + 0.233*\"run\" + 0.024*\"gun\" + 0.014*\"hide\" + 0.006*\"kiss\" + '\n",
      "  '0.005*\"lost\" + 0.004*\"hero\" + 0.002*\"breath\" + 0.002*\"die\" + 0.002*\"loved\"'),\n",
      " (9,\n",
      "  '0.548*\"baby\" + 0.163*\"give\" + 0.024*\"ill\" + 0.019*\"call\" + 0.016*\"roll\" + '\n",
      "  '0.012*\"angel\" + 0.012*\"wash\" + 0.010*\"lonely\" + 0.004*\"home\" + '\n",
      "  '0.004*\"soul\"'),\n",
      " (10,\n",
      "  '0.674*\"love\" + 0.040*\"deep\" + 0.023*\"heart\" + 0.016*\"whoa\" + 0.015*\"touch\" '\n",
      "  '+ 0.011*\"one\" + 0.010*\"come\" + 0.008*\"life\" + 0.008*\"change\" + '\n",
      "  '0.008*\"strange\"'),\n",
      " (11,\n",
      "  '0.287*\"wish\" + 0.175*\"would\" + 0.022*\"girlfriend\" + 0.018*\"sunset\" + '\n",
      "  '0.017*\"secret\" + 0.007*\"yous\" + 0.004*\"satisfied\" + 0.002*\"mansion\" + '\n",
      "  '0.000*\"cool_kid\" + 0.000*\"fall_rolle\"'),\n",
      " (12,\n",
      "  '0.291*\"wait\" + 0.104*\"moment\" + 0.028*\"faith\" + 0.025*\"ocean\" + '\n",
      "  '0.009*\"heaven\" + 0.009*\"bitter\" + 0.001*\"crowded\" + 0.001*\"fight\" + '\n",
      "  '0.000*\"lololove\" + 0.000*\"tototouch\"'),\n",
      " (13,\n",
      "  '0.152*\"let\" + 0.055*\"body\" + 0.047*\"dance\" + 0.041*\"rock\" + 0.040*\"tonight\" '\n",
      "  '+ 0.040*\"low\" + 0.032*\"stop\" + 0.032*\"move\" + 0.028*\"see\" + 0.026*\"come\"'),\n",
      " (14,\n",
      "  '0.142*\"free\" + 0.069*\"dead\" + 0.046*\"worried\" + 0.033*\"bleed\" + '\n",
      "  '0.032*\"haunt\" + 0.019*\"swim\" + 0.013*\"black_white\" + 0.010*\"ashamed\" + '\n",
      "  '0.004*\"depth\" + 0.003*\"aware\"'),\n",
      " (15,\n",
      "  '0.108*\"money\" + 0.077*\"hand\" + 0.040*\"watch\" + 0.038*\"fly\" + 0.032*\"live\" + '\n",
      "  '0.032*\"throw\" + 0.029*\"put\" + 0.029*\"song\" + 0.023*\"big\" + 0.018*\"high\"'),\n",
      " (16,\n",
      "  '0.033*\"can\" + 0.033*\"feel\" + 0.026*\"time\" + 0.024*\"make\" + 0.021*\"see\" + '\n",
      "  '0.019*\"life\" + 0.018*\"have\" + 0.018*\"think\" + 0.017*\"let\" + 0.015*\"heart\"'),\n",
      " (17,\n",
      "  '0.100*\"want\" + 0.086*\"girl\" + 0.081*\"get\" + 0.030*\"look\" + 0.030*\"way\" + '\n",
      "  '0.024*\"boy\" + 0.024*\"bad\" + 0.022*\"right\" + 0.021*\"need\" + 0.016*\"man\"'),\n",
      " (18,\n",
      "  '0.209*\"music\" + 0.054*\"match\" + 0.029*\"happiness\" + 0.009*\"concern\" + '\n",
      "  '0.009*\"growin\" + 0.000*\"happy_clap\" + 0.000*\"burn_burn\" + '\n",
      "  '0.000*\"shake_shake\" + 0.000*\"tturn\" + 0.000*\"escape\"'),\n",
      " (19,\n",
      "  '0.099*\"jean\" + 0.026*\"uh_huh\" + 0.009*\"tuck\" + 0.000*\"bottoms_bottom\" + '\n",
      "  '0.000*\"black_yellow\" + 0.000*\"build\" + 0.000*\"plenty_tight\" + '\n",
      "  '0.000*\"percent\" + 0.000*\"button\" + 0.000*\"peel\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Model Perplexity and Coherence Score\n",
    "- Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is. \n",
    "- a quick explanation: https://rare-technologies.com/what-is-topic-coherence/\n",
    "- a paper: http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -9.679628104493746\n",
      "\n",
      "Coherence Score:  0.4052910472796702\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word,mds='mmds')\n",
    "# vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "\n",
    "- A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
    "\n",
    "- A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
    "\n",
    "- if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.\n",
    "\n",
    "- Given our prior knowledge of the number of natural topics in the document, finding the best model was fairly straightforward.\n",
    "\n",
    "Upnext, we will improve upon this model by using Mallet’s version of LDA algorithm and then we will focus on how to arrive at the optimal number of topics given any large corpus of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mallet’s version, however, often gives a better quality of topics.\n",
    "\n",
    "Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself. You only need to download the zipfile, unzip it and provide the path to mallet in the unzipped directory to gensim.models.wrappers.LdaMallet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building LDA Mallet Model\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/Users/hu/Desktop/BPO2019fall/TM3/mallet-2.0.8/bin/mallet'# update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2,\n",
      "  [('long', 0.04450223956075711),\n",
      "   ('bout', 0.043779800606848725),\n",
      "   ('home', 0.041901459326686895),\n",
      "   ('leave', 0.025718826759138853),\n",
      "   ('room', 0.024129461060540383),\n",
      "   ('road', 0.021239705244906804),\n",
      "   ('meet', 0.018783412801618264),\n",
      "   ('year', 0.018494437220054904),\n",
      "   ('ring', 0.01806097384770987),\n",
      "   ('lonely', 0.0164716081491114)]),\n",
      " (1,\n",
      "  [('feel', 0.23981358189081226),\n",
      "   ('call', 0.09347536617842876),\n",
      "   ('smile', 0.034087882822902794),\n",
      "   ('talk', 0.03342210386151798),\n",
      "   ('eye', 0.03275632490013316),\n",
      "   ('face', 0.03182423435419441),\n",
      "   ('door', 0.02343541944074567),\n",
      "   ('happen', 0.017310252996005325),\n",
      "   ('set', 0.016910785619174435),\n",
      "   ('swear', 0.01677762982689747)]),\n",
      " (5,\n",
      "  [('time', 0.23367198838896952),\n",
      "   ('leave', 0.07692307692307693),\n",
      "   ('lie', 0.051589919514447816),\n",
      "   ('remember', 0.03311782557065576),\n",
      "   ('day', 0.032194220873466156),\n",
      "   ('forget', 0.03034701147908695),\n",
      "   ('mind', 0.018735981000131942),\n",
      "   ('head', 0.015569336324053305),\n",
      "   ('waste', 0.013854070457844044),\n",
      "   ('memory', 0.013590183401504157)]),\n",
      " (12,\n",
      "  [('move', 0.08730563344379301),\n",
      "   ('body', 0.07201121590619423),\n",
      "   ('dance', 0.06882487891919449),\n",
      "   ('bring', 0.053785368340555695),\n",
      "   ('low', 0.05174611266887586),\n",
      "   ('floor', 0.04652052001019628),\n",
      "   ('shake', 0.035304613815957175),\n",
      "   ('wit', 0.028677032882997704),\n",
      "   ('party', 0.024343614580678054),\n",
      "   ('front', 0.021412184552638287)]),\n",
      " (14,\n",
      "  [('good', 0.19676739283204497),\n",
      "   ('tonight', 0.10302178496134926),\n",
      "   ('stay', 0.07603654251581167),\n",
      "   ('mind', 0.06282501756851722),\n",
      "   ('friend', 0.05270555165144062),\n",
      "   ('fight', 0.03794799718903725),\n",
      "   ('night', 0.029234012649332397),\n",
      "   ('lose', 0.028390723822909348),\n",
      "   ('free', 0.020238931834153196),\n",
      "   ('promise', 0.019536191145467324)]),\n",
      " (10,\n",
      "  [('big', 0.060735887096774195),\n",
      "   ('real', 0.04158266129032258),\n",
      "   ('boy', 0.03893649193548387),\n",
      "   ('drive', 0.029233870967741934),\n",
      "   ('high', 0.02217741935483871),\n",
      "   ('full', 0.016003024193548387),\n",
      "   ('buy', 0.015498991935483871),\n",
      "   ('black', 0.015372983870967742),\n",
      "   ('car', 0.014112903225806451),\n",
      "   ('smoke', 0.013482862903225807)]),\n",
      " (8,\n",
      "  [('put', 0.11770860580695788),\n",
      "   ('hand', 0.10214491237248234),\n",
      "   ('fly', 0.05506147004969919),\n",
      "   ('head', 0.05479989537012817),\n",
      "   ('club', 0.0358357311012294),\n",
      "   ('drink', 0.030211875490452525),\n",
      "   ('ready', 0.025765105937745225),\n",
      "   ('air', 0.02432644520010463),\n",
      "   ('throw', 0.023934083180748102),\n",
      "   ('side', 0.02197227308396547)]),\n",
      " (15,\n",
      "  [('baby', 0.38846263142938336),\n",
      "   ('night', 0.13768115942028986),\n",
      "   ('ill', 0.10855356635407787),\n",
      "   ('song', 0.017760727479397557),\n",
      "   ('kiss', 0.01278772378516624),\n",
      "   ('crazy', 0.0123614663256607),\n",
      "   ('sugar', 0.010940608127308895),\n",
      "   ('round', 0.010514350667803353),\n",
      "   ('number', 0.010088093208297812),\n",
      "   ('cut', 0.008667235009946008)]),\n",
      " (4,\n",
      "  [('run', 0.08654804270462634),\n",
      "   ('light', 0.07928825622775801),\n",
      "   ('dream', 0.04569395017793594),\n",
      "   ('stand', 0.0298932384341637),\n",
      "   ('day', 0.029750889679715304),\n",
      "   ('wake', 0.02405693950177936),\n",
      "   ('blow', 0.020498220640569394),\n",
      "   ('care', 0.019217081850533807),\n",
      "   ('strong', 0.01907473309608541),\n",
      "   ('part', 0.018790035587188614)]),\n",
      " (17,\n",
      "  [('give', 0.19622895622895623),\n",
      "   ('turn', 0.127003367003367),\n",
      "   ('play', 0.04377104377104377),\n",
      "   ('young', 0.03569023569023569),\n",
      "   ('music', 0.03191919191919192),\n",
      "   ('tear', 0.029764309764309764),\n",
      "   ('song', 0.028686868686868688),\n",
      "   ('die', 0.027878787878787878),\n",
      "   ('pain', 0.023434343434343436),\n",
      "   ('heart', 0.0232996632996633)])]\n",
      "\n",
      "Coherence Score:  0.33648642895789427\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, here afterchanging the LDA algorithm, the coherence score dropeed from .48 to .38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the optimal number of topics for LDA?\n",
    "- build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value.\n",
    "\n",
    "- Choosing a ‘k’ that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics.\n",
    "\n",
    "- If you see the same keywords being repeated in multiple topics, it’s probably a sign that the ‘k’ is too large.\n",
    "\n",
    "- The compute_coherence_values() (see below) trains multiple LDA models and provides the models and their corresponding coherence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-5788a6e71713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Can take a long time to run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-f6c10e56a163>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcoherencemodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# NOTE \"--keep-sequence-bigrams\" / \"--use-ngrams true\" poorer results + runs out of memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training MALLET LDA with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# NOTE - we are still keeping the wordtopics variable to not break backward compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COMMAND: %s %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1910\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1911\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the coherence score seems to keep increasing, it may make better sense to pick the model that gave the highest CV before flattening out. This is exactly the case here.\n",
    "\n",
    "So for further steps, here we choose the model with 20 topics (exactlt what we have gotten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.3364\n",
      "Num Topics = 8  has Coherence Value of 0.3523\n",
      "Num Topics = 14  has Coherence Value of 0.3126\n",
      "Num Topics = 20  has Coherence Value of 0.3247\n",
      "Num Topics = 26  has Coherence Value of 0.3267\n",
      "Num Topics = 32  has Coherence Value of 0.3331\n",
      "Num Topics = 38  has Coherence Value of 0.3369\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the topics for the chosen LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.167*\"night\" + 0.044*\"long\" + 0.035*\"die\" + 0.035*\"kiss\" + 0.035*\"touch\" + '\n",
      "  '0.033*\"young\" + 0.025*\"drive\" + 0.025*\"sound\" + 0.022*\"lip\" + 0.019*\"lie\"'),\n",
      " (1,\n",
      "  '0.063*\"money\" + 0.044*\"shit\" + 0.042*\"fuck\" + 0.041*\"bitch\" + 0.036*\"nigga\" '\n",
      "  '+ 0.032*\"ass\" + 0.020*\"hoe\" + 0.019*\"hit\" + 0.016*\"real\" + 0.015*\"buy\"'),\n",
      " (2,\n",
      "  '0.089*\"bad\" + 0.038*\"catch\" + 0.030*\"cold\" + 0.030*\"fire\" + 0.023*\"blow\" + '\n",
      "  '0.023*\"sing\" + 0.022*\"slow\" + 0.018*\"set\" + 0.015*\"stare\" + 0.013*\"gun\"'),\n",
      " (3,\n",
      "  '0.342*\"girl\" + 0.074*\"body\" + 0.046*\"ride\" + 0.033*\"talk\" + 0.022*\"lady\" + '\n",
      "  '0.017*\"sexy\" + 0.015*\"sex\" + 0.014*\"chick\" + 0.013*\"type\" + '\n",
      "  '0.012*\"girlfriend\"'),\n",
      " (4,\n",
      "  '0.216*\"give\" + 0.060*\"watch\" + 0.034*\"face\" + 0.025*\"lie\" + 0.024*\"promise\" '\n",
      "  '+ 0.022*\"lot\" + 0.021*\"true\" + 0.019*\"part\" + 0.018*\"sit\" + 0.014*\"door\"'),\n",
      " (5,\n",
      "  '0.104*\"put\" + 0.097*\"hand\" + 0.067*\"stop\" + 0.059*\"hot\" + 0.036*\"club\" + '\n",
      "  '0.028*\"party\" + 0.027*\"pop\" + 0.026*\"music\" + 0.020*\"drink\" + 0.019*\"air\"'),\n",
      " (6,\n",
      "  '0.072*\"light\" + 0.069*\"fall\" + 0.061*\"day\" + 0.041*\"dream\" + 0.040*\"fly\" + '\n",
      "  '0.033*\"high\" + 0.032*\"place\" + 0.030*\"close\" + 0.026*\"sky\" + 0.026*\"eye\"'),\n",
      " (7,\n",
      "  '0.134*\"turn\" + 0.094*\"show\" + 0.069*\"hear\" + 0.049*\"low\" + 0.046*\"song\" + '\n",
      "  '0.033*\"ready\" + 0.031*\"play\" + 0.020*\"touch\" + 0.014*\"daddy\" + '\n",
      "  '0.014*\"middle\"'),\n",
      " (8,\n",
      "  '0.234*\"time\" + 0.075*\"mind\" + 0.068*\"leave\" + 0.035*\"fight\" + '\n",
      "  '0.032*\"remember\" + 0.029*\"forget\" + 0.022*\"day\" + 0.022*\"end\" + '\n",
      "  '0.018*\"spend\" + 0.017*\"bout\"'),\n",
      " (9,\n",
      "  '0.089*\"run\" + 0.079*\"stay\" + 0.075*\"world\" + 0.061*\"bring\" + 0.051*\"start\" '\n",
      "  '+ 0.042*\"shake\" + 0.039*\"people\" + 0.036*\"play\" + 0.032*\"hate\" + '\n",
      "  '0.031*\"step\"'),\n",
      " (10,\n",
      "  '0.099*\"heart\" + 0.053*\"head\" + 0.038*\"cry\" + 0.032*\"lose\" + 0.030*\"smile\" + '\n",
      "  '0.029*\"tear\" + 0.027*\"hurt\" + 0.023*\"pain\" + 0.019*\"soul\" + 0.017*\"truth\"'),\n",
      " (11,\n",
      "  '0.072*\"rock\" + 0.070*\"work\" + 0.059*\"beat\" + 0.037*\"roll\" + 0.029*\"wit\" + '\n",
      "  '0.023*\"head\" + 0.023*\"round\" + 0.018*\"tryna\" + 0.018*\"front\" + '\n",
      "  '0.018*\"stick\"'),\n",
      " (12,\n",
      "  '0.148*\"life\" + 0.068*\"break\" + 0.065*\"live\" + 0.046*\"hard\" + 0.022*\"talk\" + '\n",
      "  '0.019*\"save\" + 0.018*\"moment\" + 0.016*\"chance\" + 0.016*\"today\" + '\n",
      "  '0.015*\"lose\"'),\n",
      " (13,\n",
      "  '0.117*\"ill\" + 0.113*\"call\" + 0.071*\"walk\" + 0.039*\"care\" + 0.026*\"side\" + '\n",
      "  '0.025*\"home\" + 0.024*\"thing\" + 0.021*\"phone\" + 0.019*\"lonely\" + '\n",
      "  '0.018*\"number\"'),\n",
      " (14,\n",
      "  '0.418*\"make\" + 0.139*\"thing\" + 0.050*\"change\" + 0.027*\"rain\" + 0.020*\"act\" '\n",
      "  '+ 0.016*\"mad\" + 0.011*\"kill\" + 0.009*\"hit\" + 0.009*\"understand\" + '\n",
      "  '0.008*\"lose_breath\"'),\n",
      " (15,\n",
      "  '0.227*\"feel\" + 0.188*\"good\" + 0.099*\"tonight\" + 0.077*\"hold\" + '\n",
      "  '0.019*\"wrong\" + 0.018*\"alive\" + 0.017*\"lie\" + 0.016*\"swear\" + '\n",
      "  '0.015*\"breathe\" + 0.015*\"side\"'),\n",
      " (16,\n",
      "  '0.102*\"move\" + 0.081*\"dance\" + 0.080*\"wait\" + 0.054*\"floor\" + 0.054*\"stand\" '\n",
      "  '+ 0.017*\"eye\" + 0.016*\"burn\" + 0.012*\"control\" + 0.012*\"shut\" + '\n",
      "  '0.010*\"shawty\"'),\n",
      " (17,\n",
      "  '0.110*\"man\" + 0.105*\"find\" + 0.059*\"friend\" + 0.042*\"real\" + 0.032*\"woman\" '\n",
      "  '+ 0.032*\"open\" + 0.030*\"beautiful\" + 0.025*\"leave\" + 0.021*\"word\" + '\n",
      "  '0.018*\"diamond\"'),\n",
      " (18,\n",
      "  '0.121*\"boy\" + 0.061*\"big\" + 0.023*\"car\" + 0.022*\"drop\" + 0.015*\"black\" + '\n",
      "  '0.012*\"man\" + 0.012*\"town\" + 0.012*\"lean\" + 0.011*\"white\" + 0.011*\"top\"'),\n",
      " (19,\n",
      "  '0.455*\"love\" + 0.311*\"baby\" + 0.030*\"crazy\" + 0.013*\"deep\" + 0.008*\"write\" '\n",
      "  '+ 0.008*\"heart\" + 0.006*\"hope\" + 0.005*\"loving\" + 0.005*\"mine\" + '\n",
      "  '0.005*\"true\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the dominant topic in each sentence\n",
    "- One of the practical application of topic modeling is to determine what topic a given document is about.\n",
    "\n",
    "- To find that, we find the topic number that has the highest percentage contribution in that document.\n",
    "\n",
    "- The format_topics_sentences() function below nicely aggregates this information in a presentable table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>move, dance, wait, floor, stand, eye, burn, co...</td>\n",
       "      <td>im desperate changing starving truth im closer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>love, baby, crazy, deep, write, heart, hope, l...</td>\n",
       "      <td>keep fallin love sometimes love ya sometimes m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>girl, body, ride, talk, lady, sexy, sex, chick...</td>\n",
       "      <td>girls party look body shakin thing like never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>light, fall, day, dream, fly, high, place, clo...</td>\n",
       "      <td>back atmosphere drops jupiter hair hey acts li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2514</td>\n",
       "      <td>bad, catch, cold, fire, blow, sing, slow, set,...</td>\n",
       "      <td>called phone said im comin hope alone cause go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>life, break, live, hard, talk, save, moment, c...</td>\n",
       "      <td>think ive already lost think already gone thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>money, shit, fuck, bitch, nigga, ass, hoe, hit...</td>\n",
       "      <td>uh uh uh huh yo yodrop glasses shake asses fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>life, break, live, hard, talk, save, moment, c...</td>\n",
       "      <td>teas gone cold im wondering got bed morning ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>life, break, live, hard, talk, save, moment, c...</td>\n",
       "      <td>ive searching heard cry within soul ive never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2588</td>\n",
       "      <td>give, watch, face, lie, promise, lot, true, pa...</td>\n",
       "      <td>lucy liu girl drew cameron destiny charlies an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            16.0              0.1394   \n",
       "1            1            19.0              0.1908   \n",
       "2            2             3.0              0.3031   \n",
       "3            3             6.0              0.1600   \n",
       "4            4             2.0              0.2514   \n",
       "5            5            12.0              0.1271   \n",
       "6            6             1.0              0.1549   \n",
       "7            7            12.0              0.1106   \n",
       "8            8            12.0              0.1389   \n",
       "9            9             4.0              0.2588   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  move, dance, wait, floor, stand, eye, burn, co...   \n",
       "1  love, baby, crazy, deep, write, heart, hope, l...   \n",
       "2  girl, body, ride, talk, lady, sexy, sex, chick...   \n",
       "3  light, fall, day, dream, fly, high, place, clo...   \n",
       "4  bad, catch, cold, fire, blow, sing, slow, set,...   \n",
       "5  life, break, live, hard, talk, save, moment, c...   \n",
       "6  money, shit, fuck, bitch, nigga, ass, hoe, hit...   \n",
       "7  life, break, live, hard, talk, save, moment, c...   \n",
       "8  life, break, live, hard, talk, save, moment, c...   \n",
       "9  give, watch, face, lie, promise, lot, true, pa...   \n",
       "\n",
       "                                                Text  \n",
       "0  im desperate changing starving truth im closer...  \n",
       "1  keep fallin love sometimes love ya sometimes m...  \n",
       "2  girls party look body shakin thing like never ...  \n",
       "3  back atmosphere drops jupiter hair hey acts li...  \n",
       "4  called phone said im comin hope alone cause go...  \n",
       "5  think ive already lost think already gone thin...  \n",
       "6  uh uh uh huh yo yodrop glasses shake asses fac...  \n",
       "7  teas gone cold im wondering got bed morning ra...  \n",
       "8  ive searching heard cry within soul ive never ...  \n",
       "9  lucy liu girl drew cameron destiny charlies an...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most representative document for each topic\n",
    "- Sometimes just the topic keywords may not be enough to make sense of what a topic is about. \n",
    "- To help with understanding the topic, you can find the documents a given topic has contributed to the most and infer the topic by reading that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>night, long, die, kiss, touch, young, drive, s...</td>\n",
       "      <td>pharrell williams vocalslike legend phoenix en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>money, shit, fuck, bitch, nigga, ass, hoe, hit...</td>\n",
       "      <td>intro yayo yayo mulala yayoverse bitch better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4989</td>\n",
       "      <td>bad, catch, cold, fire, blow, sing, slow, set,...</td>\n",
       "      <td>aint nobody dope im fresh clean fresh clean cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>girl, body, ride, talk, lady, sexy, sex, chick...</td>\n",
       "      <td>baby grind relax mind take time let get deeper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>give, watch, face, lie, promise, lot, true, pa...</td>\n",
       "      <td>watch whip kill watch nae nae okay watch whip ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.4017   \n",
       "1        1.0              0.4885   \n",
       "2        2.0              0.4989   \n",
       "3        3.0              0.5246   \n",
       "4        4.0              0.6182   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  night, long, die, kiss, touch, young, drive, s...   \n",
       "1  money, shit, fuck, bitch, nigga, ass, hoe, hit...   \n",
       "2  bad, catch, cold, fire, blow, sing, slow, set,...   \n",
       "3  girl, body, ride, talk, lady, sexy, sex, chick...   \n",
       "4  give, watch, face, lie, promise, lot, true, pa...   \n",
       "\n",
       "                                                Text  \n",
       "0  pharrell williams vocalslike legend phoenix en...  \n",
       "1  intro yayo yayo mulala yayoverse bitch better ...  \n",
       "2  aint nobody dope im fresh clean fresh clean cl...  \n",
       "3  baby grind relax mind take time let get deeper...  \n",
       "4  watch whip kill watch nae nae okay watch whip ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the most representative document for each topic\n",
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic distribution across documents\n",
    "- To understand the volume and distribution of topics in order to judge how widely it was discussed. \n",
    "- The below table exposes that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>move, dance, wait, floor, stand, eye, burn, co...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>love, baby, crazy, deep, write, heart, hope, l...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>girl, body, ride, talk, lady, sexy, sex, chick...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>light, fall, day, dream, fly, high, place, clo...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>bad, catch, cold, fire, blow, sing, slow, set,...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1461.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>rock, work, beat, roll, wit, head, round, tryn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1462.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>give, watch, face, lie, promise, lot, true, pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1463.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>heart, head, cry, lose, smile, tear, hurt, pai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>money, shit, fuck, bitch, nigga, ass, hoe, hit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1465.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>love, baby, crazy, deep, write, heart, hope, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic                                     Topic_Keywords  \\\n",
       "0.0               16.0  move, dance, wait, floor, stand, eye, burn, co...   \n",
       "1.0               19.0  love, baby, crazy, deep, write, heart, hope, l...   \n",
       "2.0                3.0  girl, body, ride, talk, lady, sexy, sex, chick...   \n",
       "3.0                6.0  light, fall, day, dream, fly, high, place, clo...   \n",
       "4.0                2.0  bad, catch, cold, fire, blow, sing, slow, set,...   \n",
       "...                ...                                                ...   \n",
       "1461.0            11.0  rock, work, beat, roll, wit, head, round, tryn...   \n",
       "1462.0             4.0  give, watch, face, lie, promise, lot, true, pa...   \n",
       "1463.0            10.0  heart, head, cry, lose, smile, tear, hurt, pai...   \n",
       "1464.0             1.0  money, shit, fuck, bitch, nigga, ass, hoe, hit...   \n",
       "1465.0            19.0  love, baby, crazy, deep, write, heart, hope, l...   \n",
       "\n",
       "        Num_Documents  Perc_Documents  \n",
       "0.0              85.0          0.0580  \n",
       "1.0             101.0          0.0689  \n",
       "2.0              72.0          0.0491  \n",
       "3.0              60.0          0.0409  \n",
       "4.0              57.0          0.0389  \n",
       "...               ...             ...  \n",
       "1461.0            NaN             NaN  \n",
       "1462.0            NaN             NaN  \n",
       "1463.0            NaN             NaN  \n",
       "1464.0            NaN             NaN  \n",
       "1465.0            NaN             NaN  \n",
       "\n",
       "[1466 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Topic distribution across documents\n",
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(sent_topics_sorteddf_mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf_mallet.to_csv('sent_topics_sorteddf_mallet_lyrics.csv')\n",
    "df_dominant_topics.to_csv('df_dominant_topics_lyrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
